# ğŸ§  Principal Component Analysis (PCA) in Machine Learning

## ğŸ“Œ What is PCA?
- PCA is a dimensionality reduction technique.
- It transforms high-dimensional data into lower dimensions (principal components).
- Commonly used for visualization, noise reduction, and speeding up models.

## ğŸ¤” Why use PCA?
- Removes redundancy in data (correlated features).
- Helps in visualizing complex datasets.
- Improves computational efficiency.
- Reduces overfitting in some models.

## âš™ï¸ How does PCA work?
1. Standardize the data i.e do mean centering (not mandatory but performance increases).
2. Find the covariance matrix.
3. Find eigenvectors and eigenvalues.
4. Sort and select top components.
5. Transform data to new subspace.

## ğŸ“Š Use Cases
- Image compression
- Preprocessing for ML models
- Exploratory data analysis

## ğŸš€ Tools Used
- Python
- NumPy, pandas
- scikit-learn
- matplotlib / seaborn
- colab for implementation



---

Feel free to add a link to the notebook or include dataset references if applicable.
